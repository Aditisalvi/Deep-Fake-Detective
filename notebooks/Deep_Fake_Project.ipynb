{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11807637,
          "sourceType": "datasetVersion",
          "datasetId": 7415582
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Deep Fake Project",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "abdelrahmantarekm_final_merged_dataset_path = kagglehub.dataset_download('abdelrahmantarekm/final-merged-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "O1HCso11nZqS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch mlflow"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-05T14:23:02.52434Z",
          "iopub.execute_input": "2025-07-05T14:23:02.524956Z",
          "iopub.status.idle": "2025-07-05T14:23:06.005073Z",
          "shell.execute_reply.started": "2025-07-05T14:23:02.524931Z",
          "shell.execute_reply": "2025-07-05T14:23:06.004021Z"
        },
        "id": "fvLiBQQMnZqV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from pathlib import Path\n",
        "import mlflow\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "\n",
        "# Custom Dataset with Limited Debug Output\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, data_dir, split='train', transform=None):\n",
        "        self.data_dir = Path(data_dir) / 'final_dataset' / split\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        print(f\"Scanning directory for split {split}: {self.data_dir}\")\n",
        "        for item in self.data_dir.glob('*'):\n",
        "            print(f\"Found item: {item}\")\n",
        "\n",
        "        # Look for real and fake subdirectories\n",
        "        for label, class_name in enumerate(['real', 'fake']):\n",
        "            class_dir = self.data_dir / class_name\n",
        "            if class_dir.exists():\n",
        "                print(f\"Scanning {class_name} directory: {class_dir}\")\n",
        "                for img_path in class_dir.glob('*.[jp][pn][gf]*'):  # Broad extension match\n",
        "                    self.images.append(img_path)\n",
        "                    self.labels.append(label)\n",
        "            else:\n",
        "                print(f\"Directory {class_name} not found in {self.data_dir}\")\n",
        "\n",
        "        # Limit image list print to first 5 for brevity\n",
        "        image_count = len(self.images)\n",
        "        sample_images = self.images[:5] if image_count > 0 else []\n",
        "        print(f\"Found {image_count} images: {sample_images[:5] if sample_images else []}\")\n",
        "        print(f\"Labels length: {len(self.labels)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = plt.imread(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data Transforms\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Model and Trainer\n",
        "class DeepfakeTrainer:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.to(device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=5)\n",
        "        self.train_losses = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs=5):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            running_loss = 0.0\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            epoch_loss = running_loss / len(train_loader)\n",
        "            self.train_losses.append(epoch_loss)\n",
        "\n",
        "            self.model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "                    outputs = self.model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "            val_accuracy = 100 * correct / total\n",
        "            self.val_accuracies.append(val_accuracy)\n",
        "            self.scheduler.step(epoch_loss)\n",
        "            print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    def test(self, test_loader):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        test_accuracy = 100 * correct / total\n",
        "        auc = roc_auc_score(all_labels, all_preds)\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "        print(f'Final Test Accuracy: {test_accuracy:.2f}%, AUC: {auc:.4f}')\n",
        "        return test_accuracy, auc, cm\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
        "    num_ftrs = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
        "    mlflow.set_tracking_uri(\"file:///kaggle/working/mlruns1\")\n",
        "    mlflow.set_experiment(\"Deepfake_Detection\")\n",
        "    with mlflow.start_run():\n",
        "        DATA_DIR = Path(\"/kaggle/input/final-merged-dataset/\")\n",
        "\n",
        "        # Create datasets for each split\n",
        "        train_dataset = DeepfakeDataset(DATA_DIR, split='train', transform=data_transforms)\n",
        "        val_dataset = DeepfakeDataset(DATA_DIR, split='validation', transform=data_transforms)\n",
        "        test_dataset = DeepfakeDataset(DATA_DIR, split='test', transform=data_transforms)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "        trainer = DeepfakeTrainer(model, device)\n",
        "        trainer.train(train_loader, val_loader)\n",
        "        test_acc, auc, cm = trainer.test(test_loader)\n",
        "\n",
        "        # Save model\n",
        "        model_path_pth = Path(\"/kaggle/working/deepfake_model.pth\")\n",
        "        torch.save(model.state_dict(), model_path_pth)\n",
        "        model_path_pickle = Path(\"/kaggle/working/deepfake_model.pkl\")\n",
        "        with open(model_path_pickle, 'wb') as f:\n",
        "            pickle.dump(trainer.model, f)\n",
        "\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
        "        mlflow.log_metric(\"auc\", auc)\n",
        "        mlflow.log_artifact(model_path_pth)\n",
        "        mlflow.log_artifact(model_path_pickle)\n",
        "\n",
        "# Add directory listing command (limited output)\n",
        "print(\"Directory structure (top level):\")\n",
        "!ls /kaggle/input/final-merged-dataset/final_dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-05T14:23:06.006918Z",
          "iopub.execute_input": "2025-07-05T14:23:06.007244Z",
          "iopub.status.idle": "2025-07-05T20:45:35.825456Z",
          "shell.execute_reply.started": "2025-07-05T14:23:06.007208Z",
          "shell.execute_reply": "2025-07-05T20:45:35.824512Z"
        },
        "id": "VhWvGwcGnZqW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import mlflow\n",
        "from data_handler import get_transforms\n",
        "from train_efficientnet import DeepfakeEfficientNet\n",
        "import logging\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Custom Dataset\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        logger.info(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
        "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
        "        mlflow.log_metric(\"train_accuracy\", epoch_acc, step=epoch)\n",
        "        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    return model\n",
        "\n",
        "def load_data(data_dir, split, transform):\n",
        "    fake_dir = os.path.join(data_dir, split, \"fake\")\n",
        "    real_dir = os.path.join(data_dir, split, \"real\")\n",
        "\n",
        "    fake_images = [Path(os.path.join(fake_dir, img)) for img in os.listdir(fake_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    real_images = [Path(os.path.join(real_dir, img)) for img in os.listdir(real_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    image_paths = fake_images + real_images\n",
        "    labels = [0] * len(fake_images) + [1] * len(real_images)\n",
        "    logger.info(f\"Found {len(image_paths)} images in {split}\")\n",
        "\n",
        "    return image_paths, labels\n",
        "\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Training on: {device}\")\n",
        "\n",
        "    # Data directory\n",
        "    data_dir = \"/kaggle/input/final-merged-dataset/final_dataset/\"\n",
        "\n",
        "    # Load datasets\n",
        "    train_paths, train_labels = load_data(data_dir, \"train\", None)\n",
        "    val_paths, val_labels = load_data(data_dir, \"validation\", None)\n",
        "\n",
        "    # Data augmentation and transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((300, 300)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((300, 300)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n",
        "    val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Model\n",
        "    model = DeepfakeEfficientNet().to(device)\n",
        "    logger.info(\"Model initialized\")\n",
        "\n",
        "    # Loss and optimizer\n",
        "    num_fake = len([p for p in train_paths if \"fake\" in str(p)])\n",
        "    num_real = len(train_paths) - num_fake\n",
        "    total_samples = num_fake + num_real\n",
        "    class_weights = torch.tensor([num_real / total_samples, num_fake / total_samples]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_params({\n",
        "            \"batch_size\": 64,\n",
        "            \"learning_rate\": 0.0005,\n",
        "            \"epochs\": 15,\n",
        "            \"class_weights\": class_weights.tolist(),\n",
        "            \"weight_decay\": 1e-4\n",
        "        })\n",
        "        model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, device=device)\n",
        "\n",
        "        # Save the final model\n",
        "        torch.save(model.state_dict(), 'final_model.pth')\n",
        "        mlflow.log_artifact('final_model.pth')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "FUmjfTginZqY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}